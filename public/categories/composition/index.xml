<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Composition on harry morley</title>
    <link>/categories/composition/</link>
    <description>Recent content in Composition on harry morley</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-GB</language>
    <lastBuildDate>Tue, 17 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/composition/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Cellular Orchestra</title>
      <link>/posts/cellular-orchestra/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/cellular-orchestra/</guid>
      <description>Cellular Orchestra</description>
    </item>
    
    <item>
      <title>t-SNE Sampler (machine learning project)</title>
      <link>/posts/tsne-sampler/</link>
      <pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/tsne-sampler/</guid>
      <description>I completed this project as part of Rebecca Fiebrink&amp;rsquo;s Data and Machine Learning module at Goldsmiths. It uses the t-SNE algorithm to reduce the number of dimensions of audio analysis data, so that sounds are arranged in 2D space according to their likeness to one another. I used around 600 sounds, consisting of royalty free samples and my own field recordings.
For example, all the kick drums are together, all of the wooden percussion sounds are near eachother, and the hi-hat sounds are grouped - and suitably far away from the kick samples.</description>
    </item>
    
    <item>
      <title>Topographic Drummer</title>
      <link>/posts/topographic-drummer/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/topographic-drummer/</guid>
      <description>This project is an exploration into using 2D data from different shapes to sequence and synthesize percussion sounds. It is a performable program designed for improvisation and on-the-fly beat creation, particularly with a minimal and microsound aesthetic. The user can put shapes on a canvas, modify parameters, send the shapes off in random directions and toggle a glitchy delay effect.
Each drum uses simple subtractive synthesis methods from the Maximilian library, consisting of a sine/saw/triangle wave, state variable filter and envelope for shaping percussive sounds.</description>
    </item>
    
    <item>
      <title>Game of Live</title>
      <link>/posts/game-of-live/</link>
      <pubDate>Mon, 03 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/posts/game-of-live/</guid>
      <description>A sonification of John Conway’s Game of Life, the famous cellular automaton. Built in Ableton’s Max for Live, the system treats an iterating 2D grid as a generative arpeggiator, which outputs MIDI to a synth. Each cell of the grid can be alive or dead, the state of which is determined by a simple set of rules based on the number of neighbours it has.
Visuals coded in Processing.</description>
    </item>
    
    <item>
      <title>Set of Three</title>
      <link>/posts/set-of-three/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/posts/set-of-three/</guid>
      <description>This piece was a study in sample manipulation using Max/MSP and a custom multitouch interface for iPad (using Mira). The patch I built manipulated intimate piano samples, using granular synthesis and time stretching to create a glitchy, delicate atmosphere.</description>
    </item>
    
    <item>
      <title>_butterflies (Lorenz Attractor sonification)</title>
      <link>/posts/butterflies/</link>
      <pubDate>Wed, 01 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/posts/butterflies/</guid>
      <description>A sonification of the Lorenz Attractor, a chaotic system made up of 3 differential equations. Programmed in Max/MSP + Jitter, the system derives melodic content from the x, y and z values of 2 simultaneously running Lorenz systems, as well as the distance between them, illustrating the butterfly effect.</description>
    </item>
    
    <item>
      <title>Image Sonifications</title>
      <link>/posts/image-sonifications/</link>
      <pubDate>Fri, 10 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/posts/image-sonifications/</guid>
      <description>Below are a set of sonifications I made of 3 famous works of art. I built a simple sonification system in Processing that simplifies an image of the artwork into an array of large circular pixels. The program then ‘plays’ the pixels as notes by selecting them at random, which triggers notes using HSB (hue, saturation, brightness) data to derive pitches and rhythms.
When a pixel is triggered, 2 notes are played simultaneously.</description>
    </item>
    
  </channel>
</rss>